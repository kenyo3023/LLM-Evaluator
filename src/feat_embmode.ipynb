{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSplitter:\n",
    "\n",
    "    @staticmethod\n",
    "    def split_to_sentence(text:str, at_least_length:int=10):\n",
    "        sentences = nltk.tokenize.sent_tokenize(text)\n",
    "        sentences = [sent for sent in sentences if len(sent) > at_least_length]\n",
    "        return sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def split_to_paragraph(text:str, at_least_length:int=10):\n",
    "        paragraphs = re.split(r\"\\n\\n|\\n\", text)\n",
    "        paragraphs = [p for p in paragraphs if len(p) > at_least_length]\n",
    "        return paragraphs\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SplitGranularity:\n",
    "    paragraph :str = ChunkSplitter.split_to_paragraph\n",
    "    sentence  :str = ChunkSplitter.split_to_sentence\n",
    "\n",
    "\n",
    "class SummaCImagerForEMB:\n",
    "    def __init__(self,\n",
    "                 model_name_or_path:str=\"tals/albert-xlarge-vitaminc-mnli\",\n",
    "                 document_granularity:SplitGranularity=\"sentence\",\n",
    "                 summary_granularity:SplitGranularity=\"sentence\",\n",
    "                 max_doc_sents=100,\n",
    "                 device=\"cpu\"):\n",
    "\n",
    "        self.device = device\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.load_emb()\n",
    "\n",
    "        self.entailment_idx = 0\n",
    "        self.contradiction_idx = 1\n",
    "        self.neutral_idx = 2\n",
    "        self.channel = sum(x is not None for x in [self.entailment_idx, self.contradiction_idx, self.neutral_idx])\n",
    "\n",
    "        self.document_granularity = document_granularity\n",
    "        self.document_splitter = getattr(SplitGranularity, self.document_granularity)\n",
    "\n",
    "        self.summary_granularity = summary_granularity\n",
    "        self.summary_splitter = getattr(SplitGranularity, summary_granularity)\n",
    "\n",
    "        self.max_doc_sents = max_doc_sents\n",
    "        self.max_input_length = 500\n",
    "\n",
    "\n",
    "    def load_emb(self):\n",
    "        self.model = SentenceTransformer(self.model_name_or_path)\n",
    "        self.model.to(self.device)\n",
    "        if self.device == \"cuda\":\n",
    "            self.model.half()\n",
    "\n",
    "\n",
    "    def create_pair_dataset(self, document_chunks:list[str], summary_chunks:list[str]):\n",
    "\n",
    "        def count_generator(i=0):\n",
    "            while True:\n",
    "                yield i\n",
    "                i += 1\n",
    "        counter = count_generator(0)\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                'document': document_chunks[i],\n",
    "                'summary': summary_chunks[j],\n",
    "                'document_idx': i,\n",
    "                'summary_idx': j,\n",
    "                'pair_idx': next(counter),\n",
    "            }\n",
    "            for i in range(len(document_chunks))\n",
    "            for j in range(len(summary_chunks))\n",
    "        ]\n",
    "\n",
    "\n",
    "    def build_image(self, document:str, summary:str, batch_size=4, return_dict_or_matrix:str='dict'):\n",
    "        document_chunks = self.document_splitter(document)\n",
    "        summary_chunks = self.summary_splitter(summary)\n",
    "        pair_dataset = self.create_pair_dataset(document_chunks, summary_chunks)\n",
    "\n",
    "        def batch_generator(dataset:list[dict], batch_size:str=20):\n",
    "\n",
    "            dataset_size = len(dataset)\n",
    "            chunk_size = (dataset_size // batch_size) + bool((dataset_size % batch_size))\n",
    "\n",
    "            for i in range(chunk_size):\n",
    "                batch = dataset[batch_size*i:batch_size*(i+1)]\n",
    "                # pair_data = [(data['document'], data['summary']) for data in batch]\n",
    "\n",
    "                yield [data['document'] for data in batch], [data['summary'] for data in batch]\n",
    "\n",
    "\n",
    "        document_embs, summary_embs = [], []\n",
    "        for i, batch in enumerate(tqdm(batch_generator(pair_dataset, batch_size=batch_size), desc='Processing')):\n",
    "            document_batch, summary_batch = batch\n",
    "            with torch.no_grad():\n",
    "                document_emb = self.model.encode(document_batch, normalize_embeddings=True)\n",
    "                summary_emb = self.model.encode(summary_batch, normalize_embeddings=True)\n",
    "                # similarity = embs1 @ embs2.T\n",
    "\n",
    "        #     if i:\n",
    "        #         probs = torch.cat((probs, torch.nn.functional.softmax(model_outputs[\"logits\"], dim=-1)))\n",
    "        #     else:\n",
    "        #         probs = torch.nn.functional.softmax(model_outputs[\"logits\"], dim=-1)\n",
    "\n",
    "        # if return_dict_or_matrix == 'matrix':\n",
    "        #     _shape = (self.channel, document_chunks.__len__(), summary_chunks.__len__())\n",
    "        #     image = probs[:, [self.entailment_idx, self.contradiction_idx, self.neutral_idx]].numpy().T.reshape(_shape)\n",
    "        # elif return_dict_or_matrix == 'dict':\n",
    "        #     _shape = (document_chunks.__len__(), summary_chunks.__len__())\n",
    "        #     image = {\n",
    "        #         'entailment': probs[:, self.entailment_idx].numpy().T.reshape(_shape),\n",
    "        #         'contradiction': probs[:, self.contradiction_idx].numpy().T.reshape(_shape),\n",
    "        #         'neutral': probs[:, self.neutral_idx].numpy().T.reshape(_shape),\n",
    "        #     }\n",
    "        # else:\n",
    "        #     raise ValueError(f'Invalid value \\'return_dict_or_matrix\\'={return_dict_or_matrix}')\n",
    "\n",
    "        # return probs, image\n",
    "        return document_emb, summary_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 2it [00:01,  1.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00809112,  0.03825084,  0.00626019, ...,  0.01670528,\n",
       "         -0.06983218,  0.00651465],\n",
       "        [ 0.00821151,  0.02340669, -0.00473241, ..., -0.03436563,\n",
       "         -0.03132045, -0.01498133],\n",
       "        [ 0.00821151,  0.02340669, -0.00473241, ..., -0.03436563,\n",
       "         -0.03132045, -0.01498133],\n",
       "        [ 0.00821151,  0.02340669, -0.00473241, ..., -0.03436563,\n",
       "         -0.03132045, -0.01498133]], dtype=float32),\n",
       " array([[ 0.00405655,  0.02207707, -0.00563519, ...,  0.01684863,\n",
       "         -0.08713452, -0.01289776],\n",
       "        [ 0.00626215,  0.03595928,  0.00767179, ..., -0.01445544,\n",
       "         -0.0352744 ,  0.00671129],\n",
       "        [ 0.00926525,  0.0548636 ,  0.00087204, ...,  0.0018177 ,\n",
       "         -0.06174414,  0.0076586 ],\n",
       "        [ 0.00405655,  0.02207707, -0.00563519, ...,  0.01684863,\n",
       "         -0.08713452, -0.01289776]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = \"\"\"Scientists are studying Mars to learn about the Red Planet and find landing sites for future missions.\n",
    "One possible site, known as Arcadia Planitia, is covered instrange sinuous features.\n",
    "The shapes could be signs that the area is actually made of glaciers, which are large masses of slow-moving ice.\n",
    "Arcadia Planitia is in Mars' northern lowlands.\"\"\"\n",
    "summary = \"There are strange shape patterns on Arcadia Planitia. The shapes could indicate the area might be made of glaciers. This makes Arcadia Planitia ideal for future missions.\"\n",
    "summary2 = \"There are strange shape patterns on Arcadia Planitia. The shapes could indicate the area might be made of glaciers.\"\n",
    "\n",
    "model_name_or_path = \"DMetaSoul/Dmeta-embedding-zh\"\n",
    "imager = SummaCImagerForEMB(model_name_or_path)\n",
    "# batch, model_outputs, batch_probs, image = imager.build_image(document, summary, batch_size=3)\n",
    "document_emb, summary_emb = imager.build_image(document, summary, batch_size=8, return_dict_or_matrix='dict')\n",
    "document_emb, summary_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59722584, 0.6904497 , 0.88714266, 0.59722584],\n",
       "       [0.6291899 , 0.5766112 , 0.53290033, 0.6291899 ],\n",
       "       [0.6291899 , 0.5766112 , 0.53290033, 0.6291899 ],\n",
       "       [0.6291899 , 0.5766112 , 0.53290033, 0.6291899 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_emb @ summary_emb.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
